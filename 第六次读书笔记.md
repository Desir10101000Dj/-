# 第六次读书笔记 # 
## 5.1神经元模型 ##
神经网络是由具有适应性的简单单元组成的广泛并行互连的网络，它的组织能够模拟生物神经系统对真实世界物体所作出的交互反应

​ 神经网络中最基本的成分是神经元模型，即“简单单元”，在生物神经网络中，每个神经元与其他神经元相连，当它“兴奋”时，就会向相连的神经元发送化学物质，从而改变这些神经元内的电位；如果某神经元的电位超过一个“阈值”，那么它就会被激活，即“兴奋” 起来，向其他神经元发送化学物质。

​  

激活函数

理想激活函数是阶跃函数，0 表示抑制神经元而1表示激活神经元

阶跃函数具有不连续、不光滑等不好的性质，常用的是Sigmoid函数



Sigmoid函数可能在较大范围内变化的输入值挤压到（0,1）输出值范围内，因此有时也称为”挤压函数”

​ 把这样许多个神经元按一定的层次结构连接起来，就得到了神经网络。

## 5.2感知机与多层网络 ##
感知机有两层神经元组成



感知机只有输出层神经元进行激活函数处理，即只拥有一层功能神经元。



要解决非线性可分问题，需要考虑使用多层功能神经元



多层前馈网络结构

多层网络：包含隐层的网络

前馈网络：神经元之间不存在同层连接也不存在跨层连接

隐层和输出层神经元亦称“功能单元”

多层前馈网络有强大的表示能力

​ 只需一个包含足够多神经元的隐层，多层前馈神经网络就能以任意精度逼近任意复杂度的连续函数

设置隐层神经元数，通常用“试错法”

## 5.3误差逆传播算法  ##
BP神经网络

​ 它是迄今为止最成功的神经网络学习算法，显示任务中使用神经网络时，大多在使用BP算法进行训练

​ BP算法不仅可用于多层前馈神经网络，还可用于其他类型的神经网络



输入：d维特征向量

输出：l个输出值

隐层：假定使用q个隐层神经元

假定功能单元均使用Sigmoid函数



主要特点
信号是前向传播的，而误差是反向传播的。

主要过程

信号的前向传播，从输入层经过隐含层，最后到达输出层

误差的反向传播，从输出层到隐含层，最后到输入层，依次调节隐含层到输出层的权重和偏置，输入层到隐含层的权重和偏置

流程

网络的初始化

g(x)=11+e−xg(x)=11+e−x
隐含层的输出

Hj=g(∑ni=1ωijxi+aj)Hj=g(∑i=1nωijxi+aj)
输出层的输出

Ok=∑lj=1Hjωjk+bkOk=∑j=1lHjωjk+bk
误差的计算

取误差公式为

​ E=12∑mk=1(Yk−Ok)2E=12∑k=1m(Yk−Ok)2
其中YkYk为期望输出，我们计Yk−Ok=ekYk−Ok=ek,则E可以表示为

E=12∑mk=1e2kE=12∑k=1mek2
权值的更新



标准BP算法 与 累计BP算法

标准BP算法
每次针对单个训练样例更新权值与阈值
参数更新频繁，不同样例可以抵消，需要多次迭代
累计BP算法
其优化目标是最小化整个训练集上的累计误差
读取整个训练集一遍才对参数进行更新，参数更新频率较低
在很多任务中，累计误差下降到一定程度后，进一步下降会非常缓慢，这是标准BP算法往往会获得较好的解，尤其当训练集非常大时效果更明显。

缓解过拟合

主要策略

早停

若训练误差连续a轮的变化小于b,则停止训练

使用验证集：若训练误差降低，验证误差升高，则停止训练

正则化

在误差目标函数找那个增加一项描述网络复杂度

偏好比较小的连接权和阈值，使网络输出更“光滑”

## 5.4全局最小与局部极小  ##


神经网络的训练过程可看作一个参数寻优过程：

​ 在参数空间中，寻找一组最优参数使得误差最小

特点

存在多个“局部极小”
只有一个“全局最小”
其他常见神经网络模型
RBF :分类任务中除BP之外最常用

单隐层前馈神经网络

使用径向基函数作为隐层神经元激活函数

输出层是隐层神经元输出的线性组合

训练

确定神经元中心，常用的方式包括随机残阳、聚类等

利用BP算法等确定参数

​

ART：”竞争学习”的代表

SOM：最常用的聚类方法之一

## 5.5其他常见的神经网络 ##

竞争型的无监督神经网络
将高维数据映射到低维空间，高维空间中相似的样本点映射到网络输出层中临近神经元
每个神经元拥有一个权向量
目标：为每个输出层神经元找到合适的权向量以保持拓扑结构
训练
网络接收输入样本后，将会确定输出层的“获胜”神经元（“胜者通吃”）
获胜神经元的权向量将向当前输入样本移动
​

级联相关网络：“构造性”神经网络的代表



构造性神经网络

​ 将网络的结构也当做学习的目标之一，我往在训练过程中找到适合数据的网络结构

训练
开始时只有输入层和输出层
级联-新的隐层节点逐渐加入，从而创建起层级结构
相关-最大化新节点的输出与网络误差之间的相关性
​

Elman网络：递归神经网络的代表



网络可以有环形结构，可让使一些神经元的输出反馈回来最为输入
t 时刻网络的输出状态： 由 t 时刻的输入状态和 t-1时刻的网络状态共同决定
Elman网络是最常用的递归神经网络之一

结构与前馈神经网络很相似，但隐层神经元的输出被反馈回来
使用推广的BP算法训练
​

Bolyzmann机：”基于能量的模型”的代表



## 5.6深度学习 ##
卷积神经网络



每个卷积层包含多个特征映射，每个特征映射是一个由多个神经元构成的“平面”，通过一种卷积滤波器提取输入的一种特征
采样层亦称“汇合层”，其作用是基于局部相关性原理进行亚采样，从而在减少数据量的同时保留有用信息
连接层就是传统神经网络对隐层与输出层的全连接
典型的深度学习模型就是很深层的神经网络

## 习题 ##
 ### 使用numpy编写的CNN--转自网络
import numpy
import sys

"""
Convolutional neural network implementation using NumPy.
An article describing this project is titled "Building Convolutional Neural Network using NumPy from Scratch". It is available in these links: https://www.linkedin.com/pulse/building-convolutional-neural-network-using-numpy-from-ahmed-gad/
https://www.kdnuggets.com/2018/04/building-convolutional-neural-network-numpy-scratch.html
It is also translated into Chinese: http://m.aliyun.com/yunqi/articles/585741

The project is tested using Python 3.5.2 installed inside Anaconda 4.2.0 (64-bit)
NumPy version used is 1.14.0

For more info., contact me:
    Ahmed Fawzy Gad
    KDnuggets: https://www.kdnuggets.com/author/ahmed-gad
    LinkedIn: https://www.linkedin.com/in/ahmedfgad
    Facebook: https://www.facebook.com/ahmed.f.gadd
    ahmed.f.gad@gmail.com
    ahmed.fawzy@ci.menofia.edu.eg
"""


def conv_(img, conv_filter):
    filter_size = conv_filter.shape[1]
    result = numpy.zeros((img.shape))
    # Looping through the image to apply the convolution operation.
    for r in numpy.uint16(numpy.arange(filter_size / 2.0,
                                       img.shape[0] - filter_size / 2.0 + 1)):
        for c in numpy.uint16(numpy.arange(filter_size / 2.0,
                                           img.shape[1] - filter_size / 2.0 + 1)):
            """
            Getting the current region to get multiplied with the filter.
            How to loop through the image and get the region based on 
            the image and filer sizes is the most tricky part of convolution.
            """
            curr_region = img[r - numpy.uint16(numpy.floor(filter_size / 2.0)):r + numpy.uint16(
                numpy.ceil(filter_size / 2.0)),
                          c - numpy.uint16(numpy.floor(filter_size / 2.0)):c + numpy.uint16(
                              numpy.ceil(filter_size / 2.0))]
            # Element-wise multipliplication between the current region and the filter.
            curr_result = curr_region * conv_filter
            conv_sum = numpy.sum(curr_result)  # Summing the result of multiplication.
            result[r, c] = conv_sum  # Saving the summation in the convolution layer feature map.

    # Clipping the outliers of the result matrix.
    final_result = result[numpy.uint16(filter_size / 2.0):result.shape[0] - numpy.uint16(filter_size / 2.0),
                   numpy.uint16(filter_size / 2.0):result.shape[1] - numpy.uint16(filter_size / 2.0)]
    return final_result


def conv(img, conv_filter):
    if len(img.shape) != len(conv_filter.shape) - 1:  # Check whether number of dimensions is the same
        print("Error: Number of dimensions in conv filter and image do not match.")
        exit()
    if len(img.shape) > 2 or len(conv_filter.shape) > 3:  # Check if number of image channels matches the filter depth.
        if img.shape[-1] != conv_filter.shape[-1]:
            print("Error: Number of channels in both image and filter must match.")
            sys.exit()
    if conv_filter.shape[1] != conv_filter.shape[2]:  # Check if filter dimensions are equal.
        print('Error: Filter must be a square matrix. I.e. number of rows and columns must match.')
        sys.exit()
    if conv_filter.shape[1] % 2 == 0:  # Check if filter diemnsions are odd.
        print('Error: Filter must have an odd size. I.e. number of rows and columns must be odd.')
        sys.exit()

    # An empty feature map to hold the output of convolving the filter(s) with the image.
    feature_maps = numpy.zeros((img.shape[0] - conv_filter.shape[1] + 1,
                                img.shape[1] - conv_filter.shape[1] + 1,
                                conv_filter.shape[0]))

    # Convolving the image by the filter(s).
    for filter_num in range(conv_filter.shape[0]):
        print("Filter ", filter_num + 1)
        curr_filter = conv_filter[filter_num, :]  # getting a filter from the bank.
        """ 
        Checking if there are mutliple channels for the single filter.
        If so, then each channel will convolve the image.
        The result of all convolutions are summed to return a single feature map.
        """
        if len(curr_filter.shape) > 2:
            conv_map = conv_(img[:, :, 0], curr_filter[:, :, 0])  # Array holding the sum of all feature maps.
            for ch_num in range(1, curr_filter.shape[
                -1]):  # Convolving each channel with the image and summing the results.
                conv_map = conv_map + conv_(img[:, :, ch_num],
                                            curr_filter[:, :, ch_num])
        else:  # There is just a single channel in the filter.
            conv_map = conv_(img, curr_filter)
        feature_maps[:, :, filter_num] = conv_map  # Holding feature map with the current filter.
    return feature_maps  # Returning all feature maps.


def pooling(feature_map, size=2, stride=2):
    # Preparing the output of the pooling operation.
    pool_out = numpy.zeros((numpy.uint16((feature_map.shape[0] - size + 1) / stride + 1),
                            numpy.uint16((feature_map.shape[1] - size + 1) / stride + 1),
                            feature_map.shape[-1]))
    for map_num in range(feature_map.shape[-1]):
        r2 = 0
        for r in numpy.arange(0, feature_map.shape[0] - size + 1, stride):
            c2 = 0
            for c in numpy.arange(0, feature_map.shape[1] - size + 1, stride):
                pool_out[r2, c2, map_num] = numpy.max([feature_map[r:r + size, c:c + size, map_num]])
                c2 = c2 + 1
            r2 = r2 + 1
    return pool_out


def relu(feature_map):
    # Preparing the output of the ReLU activation function.
    relu_out = numpy.zeros(feature_map.shape)
    for map_num in range(feature_map.shape[-1]):
        for r in numpy.arange(0, feature_map.shape[0]):
            for c in numpy.arange(0, feature_map.shape[1]):
                relu_out[r, c, map_num] = numpy.max([feature_map[r, c, map_num], 0])
    return relu_out



