# 第三次读书笔记 #
---
## 2.1经验误差与过拟合 ##
 错误率：分类错误的样本占样本总数的比例。  E = a／m

    精度：1 - a／m

    训练误差／经验误差：训练集上的误差

    泛化误差：新样本上的误差。
## 2.2评估方法 ##
 区分数据集，把数据集分为两部分，一部分是训练集S另外一部分是测试集T
### 2.2.1 留出法 ###
    一个数据集分成互斥的两部分，分别作为训练集和测试集。可以通过分层采样的方法，保证两个数据集的数据分布一致。

    一般会多次区分数据集得到多次结果，然后得出平均值最为最终结果。
    
代码模拟：

    from sklearn.model_selection import train_test_split
    from sklearn import datasets
    iris = datasets.load_iris()
    X_train,X_test,y_train,y_test= train_test_split(iris.data,iris.target,test_size=0.3,random_state=0,stratify=iris.target)

    print("X_train=",X_train)
    print("X_test=",X_test)
    print("y_train=",y_train)
    print("y_test=",y_test)
 ！[留出法]()

### 2.2.2 交叉验证法 ###
    从数据集D中通过分层采样得到k个大小相似的互斥子集。

    每次选择k-1个子集的并集作为训练集，另外一个作为测试集。最终可以进行k次训练和测试。最终返回k次的平均值。这种方法通常也被成为“k折交叉验证”。k的最常用取值是10.

    如果在每次划分k个不同子集的时候，根据不同的划分规则，可以得到不同的k个子集。结合之前的留出法，就可以产生p次k折交叉验证。最常见的是10次10折交叉验证。

    当k等于样本个数时，变成留一法。

###  2.2.3 自助法 ###
    从数据集D中取出放回m次形成一个新的数据集D'，D'与D相同大小。但是会存在部分数据重复。D中会有

（1−1/m）m个数据不会被放到D'中。大约占0.368。然后用D'作训练集，D作测试集。

    自助法在数据集较小，难以有效划分训练／测试集的时候很有用。但是自助法改变了初始数据集的分布，会引入估计偏差。所以当数据足够时，还是使用留出法和交叉验证法。

###  2.2.4 调参与最终模型 ###
    调整算法参数和最终使用全部数据训练出最终模型。

## 2.3 性能度量 ##
    性能度量：衡量模型泛化能力的评价标准。

    回归任务最常用的性能度量时“均方误差”。

### 2.3.1 错误率与精度 ###
见2.1
### 2.3.2 查准率、查全率与F1 ###
    真正例TP、假正例FP、真反例TN、假反例FN

    可以组成混淆矩阵


                                                  分类结果混淆矩阵
                                                     预测结果
                                                真实情况	正例	反例
                                                
                                                正例	真正例TP	假反例FN
                                                
                                                反例	假正例FP	真反例TN
                                                
                                                查准率P = TP ／ TP+FP

                                                查全率R = TP ／ TP+FN

    查全和查准都时针对正例，查准率是预测为正例中正确的概率。查全率是正例中被预测为正例的概率。

    查准率-查全率曲线-P-R曲线-P-R图

    通过“平衡点”BEP 查准率=查全率时的取值，对比不同学习器的优劣。

    因为BEP过于简单，所以通常使用F1度量来评判学习器的好坏。

    F1 = (2 * P * R) / (P + R) = （2 * TP）／ (m + TP -TN)

    Fβ = ((1+β2)∗P∗R)  /   ((β2∗P)+R) 。β=1退化为标准F1度量，β<1查全率有更大影响，β>1查准率有更大影响。

    多个混淆矩阵综合考察时有两种方法。

    第一种，平均每个混淆矩阵的P，R，F的平均值，称为 “宏”

    第二种，平均TP、FP、TN、FN之后计算P、R、F，成为 “微”

  ### 2.3.3 ROC与AUC ###
    ROC:一般情况下泛化性能的好坏。

    根据学习器的预测结果对样例进行排序，按此顺序逐个把样本作为正例进行预测，每次计算出两个重要量的值，分别以他们为横、纵坐标作图，就得到了ROC曲线。 
    
### 2.3.4 代价敏感错误率与代价曲线  ###


## 2.4比较检验 ##



### 2.4.1假设检验 ###




### 2.4.2交叉验证t检验 ###



### 2.4.3McNemar检验 ###




### 2.4.4Friedman检验与Nemenyi后续检验 ###





## 2.5偏差与方差 ##






## 2.6阅读材料 略 ##







## 习题 ##
 

        
